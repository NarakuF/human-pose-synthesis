{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'random_annotate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7c78ae386b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_img\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRescale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDynamicCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCenterCrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mweights_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_annotate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpose_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoseDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoseGeneratorDC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoseGeneratorL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'random_annotate'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from utils.process_img import Rescale, DynamicCrop, ToTensor, CenterCrop\n",
    "from utils.func import weights_init, random_annotate, gaussian_noise\n",
    "from pose_dataset import PoseDataset, print_sample\n",
    "from model.generator import PoseGeneratorDC, PoseGeneratorL\n",
    "from model.discriminator import PoseDiscriminatorDC, PoseDiscriminatorL\n",
    "from utils.process_text import tokenizer, get_embeddings, get_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "lr = 0.0002 \n",
    "beta1 = 0.5 \n",
    "img_size = 128\n",
    "z_size = 16\n",
    "batch_size = 3\n",
    "composed = transforms.Compose([Rescale(512),\n",
    "                               DynamicCrop(30),\n",
    "                               Rescale((img_size, img_size))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_dataset = PoseDataset('./data/sample_list.csv', './data', transform = composed)\n",
    "pose_dataloader = DataLoader(pose_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print(len(pose_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     sample = pose_dataset[i]\n",
    "#     print_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model, Loss, and Optimizer\n",
    "embeddings = pose_dataset.embeddings\n",
    "#netD = PoseDiscriminatorDC(embeddings).cuda()\n",
    "netD = Discriminator().cuda()\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# netD = PoseDiscriminatorL().cuda()\n",
    "netG = PoseGeneratorDC(embeddings).cuda()\n",
    "\n",
    "netG.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "num_epochs = 50\n",
    "\n",
    "torch.manual_seed(250)\n",
    "fixed_noise = torch.randn(1, z_size, 1, 1).cuda()\n",
    "fixed_annotate = random_annotate(1, pose_dataset, random_state = 1).cuda()\n",
    "#torch.randn(batch_size, z_size, 1, 1).long().cuda()\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    for i, sample in enumerate(pose_dataloader, 0):\n",
    "        \n",
    "        # ---------------------------------------------\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # ---------------------------------------------\n",
    "        # Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        batch_size = sample['parsing'].shape[0]\n",
    "        real_image = torch.reshape(sample['pose'], (batch_size, 3, img_size, img_size)).float().cuda()\n",
    "        \n",
    "        # Add noise to real pose\n",
    "        #real_image = gaussian_noise(real_image)\n",
    "        \n",
    "        annotate = sample['annotate'].cuda()\n",
    "        fake_annotate = random_annotate(batch_size, pose_dataset).cuda()\n",
    "\n",
    "        \n",
    "        label = torch.full((batch_size, ), real_label).cuda()  \n",
    "        \n",
    "        #output = netD(real_image, annotate).view(-1)\n",
    "        output = netD(real_image).view(-1)\n",
    "        \n",
    "        errD_real = criterion(output, label) \n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        # Train with all-fake batch\n",
    "        noise = torch.randn(batch_size, z_size, 1, 1).cuda()\n",
    "        fake_image = netG(noise, fake_annotate)\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        output = netD(fake_image.detach()).view(-1)\n",
    "        #output = netD(fake_image.detach(), fake_annotate).view(-1)   \n",
    "        \n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        \n",
    "        # --------------------------------------------- #\n",
    "        # (2) Update G network: maximize log(D(G(z)))   #\n",
    "        # --------------------------------------------- #\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label) \n",
    "        \n",
    "        output = netD(fake_image).view(-1)\n",
    "        #output = netD(fake_image, fake_annotate).view(-1)  \n",
    "        \n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i and i%10==0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                      % (epoch, num_epochs, i, len(pose_dataloader),\n",
    "                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "     \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        iters += 1\n",
    "\n",
    "        \n",
    "    netG.eval()\n",
    "    with torch.no_grad():\n",
    "        fake_image = netG(fixed_noise, fixed_annotate)\n",
    "        img = torch.reshape(fake_image[0], (img_size, img_size, 3)).cpu().data.detach().numpy()\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGAN on clustered pose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "batch_size = 64\n",
    "img_shape = (3, 64, 64)\n",
    "composed = transforms.Compose([Rescale(512),\n",
    "                               DynamicCrop(30),\n",
    "                               Rescale((img_size, img_size))])\n",
    "\n",
    "pose_dataset = PoseDataset('./data/data_list_label.csv', './data', transform = composed, gray_scale = False)\n",
    "pose_dataloader = DataLoader(pose_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print(len(pose_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pose_dataset[1]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {'b1': 0.5, \n",
    "       'b2': 0.999, \n",
    "       'batch_size': 64, \n",
    "       'channels': 1, \n",
    "       'img_size': 32, \n",
    "       'latent_dim': 100, \n",
    "       'lr': 0.0002, \n",
    "       'n_classes': 200, \n",
    "       'n_cpu': 8, \n",
    "       'n_epochs': 1, \n",
    "       'sample_interval': 400}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(opt['n_classes'], opt['n_classes'])\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt['latent_dim'] + opt['n_classes'], 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(opt['n_classes'], opt['n_classes'])\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(opt['n_classes'] + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        img = img.view(img.shape[0], -1)\n",
    "        d_in = torch.cat((self.label_embedding(labels), img.float()), -1)\n",
    "\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.MSELoss()\n",
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt['lr'], betas=(opt['b1'], opt['b2']))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt['lr'], betas=(opt['b1'], opt['b2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "test_batch_size = 100\n",
    "fixed_z = torch.randn(test_batch_size, opt['latent_dim']).cuda()\n",
    "#np.random.seed(250)\n",
    "#fixed_gen_labels = torch.from_numpy(np.random.randint(0, 200, batch_size)).cuda()\n",
    "fixed_gen_labels = torch.from_numpy(np.arange(test_batch_size)).cuda()\n",
    "gen_img_list = []\n",
    "G_loss, D_loss = [], []\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for i, sample in enumerate(pose_dataloader):\n",
    "        imgs = sample['pose']\n",
    "        labels = sample['label']\n",
    "        \n",
    "        b_size = imgs.shape[0]\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.full((b_size, ), 1.0).cuda()\n",
    "        fake = torch.full((b_size, ), 0.0).cuda()\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = torch.randn(batch_size, opt['latent_dim']).cuda()\n",
    "        gen_labels = torch.from_numpy(np.random.randint(0, 200, batch_size)).cuda()\n",
    "        \n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        G_loss.append(g_loss.item())\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        \n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "        \n",
    "        # Loss for fake images\n",
    "        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        D_loss.append(d_loss.item())\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if i and i % 5 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, n_epochs, i, len(pose_dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "        \n",
    "        if i and i % 50 == 0:\n",
    "            gen_imgs = generator(fixed_z, fixed_gen_labels)\n",
    "            gen_img_list.append(gen_imgs)\n",
    "            img = np.reshape(gen_imgs[0].cpu().detach().numpy(), (64, 64, 3))\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "#         batches_done = epoch * len(dataloader) + i\n",
    "#         if batches_done % opt.sample_interval == 0:\n",
    "#             sample_image(n_row=10, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(generator, 'parsing_netG.pth')\n",
    "# torch.save(discriminator, 'parsing_netD.pth')\n",
    "# print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(20):\n",
    "    class_images = gen_img_list[k].cpu().detach().numpy()\n",
    "    # np.random.seed(4995)\n",
    "    #target_labels = np.random.choice(np.arange(100), 10, replace = False)\n",
    "    target_labels = np.arange(10)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "    for i in range(10):\n",
    "        fig.add_subplot(k+1, 10, i+1)\n",
    "        img = np.reshape(class_images[target_labels[i]], (64, 64, -1))\n",
    "        plt.imshow(img)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pose_dataset[1]\n",
    "img = sample['pose']\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
